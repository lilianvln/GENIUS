{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "T7Rc9Fw15VQV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM3sqdhw2unE"
      },
      "outputs": [],
      "source": [
        "import numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "pmON9E5d5XtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1"
      ],
      "metadata": {
        "id": "K_pv0JoS6hNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"The quick brown fox jumped over the lazy dog\",\n",
        "    \"She sells seashells by the seashore\",\n",
        "    \"Peter Piper picked a peck of pickled peppers\",\n",
        "]"
      ],
      "metadata": {
        "id": "dKGWwDkp2wJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set()\n",
        "for sentence in corpus:\n",
        "  for word in sentence.split():\n",
        "    unique_words.add(word.lower())"
      ],
      "metadata": {
        "id": "T7ZPgHhk2_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "for i, word in enumerate(unique_words):\n",
        "  word_to_index[word] = i"
      ],
      "metadata": {
        "id": "6FMzky7a3A3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_vectors = []\n",
        "for sentence in corpus:\n",
        "  sentence_vectors = []\n",
        "  for word in sentence.split():\n",
        "    vector = numpy.zeros(len(unique_words))\n",
        "    vector[word_to_index[word.lower()]] = 1\n",
        "    sentence_vectors.append(vector)\n",
        "  one_hot_vectors.append(sentence_vectors)"
      ],
      "metadata": {
        "id": "xpNlk6JR3oWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result 1"
      ],
      "metadata": {
        "id": "pp09GhG07MzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"One-hot encoding vectors for the first sentence:\")\n",
        "for vector in one_hot_vectors[0]:\n",
        "  print(vector)"
      ],
      "metadata": {
        "id": "L2wu_sgg7PI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2"
      ],
      "metadata": {
        "id": "SNRXcpBg6nID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"The dog chased the cat.\",\n",
        "    \"The mat was soft and fluffy.\",\n",
        "]"
      ],
      "metadata": {
        "id": "3yLqpqXY6pSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = set()\n",
        "for sentence in corpus:\n",
        "  for word in sentence.split():\n",
        "    unique_words.add(word)"
      ],
      "metadata": {
        "id": "ZkECBRmT6_gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "for i, word in enumerate(unique_words):\n",
        "  word_to_index[word] = i"
      ],
      "metadata": {
        "id": "JHUGJCG97Cy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_vectors = []\n",
        "for sentence in corpus:\n",
        "  sentence_vectors = []\n",
        "  for word in sentence.split():\n",
        "    vector = numpy.zeros(len(unique_words))\n",
        "    vector[word_to_index[word.lower()]] = 1\n",
        "    sentence_vectors.append(vector)\n",
        "  one_hot_vectors.append(sentence_vectors)"
      ],
      "metadata": {
        "id": "wVJ3ESMD7D3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result 2"
      ],
      "metadata": {
        "id": "JJ9HRGEl7QUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"One-hot encoding vectors for the first sentence:\")\n",
        "for vector in one_hot_vectors[0]:\n",
        "  print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOTJpUWO7SJY",
        "outputId": "f90a5b5e-469c-4357-dea6-bdf28439cd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoding vectors for the first sentence:\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNfsysJK7Ue6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}